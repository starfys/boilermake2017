[["HTM for Adelaide Arterial Traffic Flow", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/B52YKNu29L4?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"HTM for Adelaide Arterial Traffic Flow \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/463/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"HTM for Adelaide Arterial Traffic Flow \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/464/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"HTM for Adelaide Arterial Traffic Flow \u2013 screenshot 3\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/465/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"HTM for Adelaide Arterial Traffic Flow \u2013 screenshot 4\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/466/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"HTM for Adelaide Arterial Traffic Flow \u2013 screenshot 5\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/467/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h1>Traffic Anomaly Detection in Adelaide using HTM</h1>\n<p><img alt=\"Adelaide from the air\" data-canonical-url=\"https://i.imgur.com/5STpTTNh.jpg\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--qji-HNot--/https://i.imgur.com/5STpTTNh.jpg\" title=\"Adelaide in all its glory\"/></p>\n<h2>Introduction</h2>\n<p>Adelaide uses SCATS for collecting traffic data (along with signal control) using induction loops beneath the road\nto record the number of vehicles that go though a particular lane at an intersection. This data is provided in 5\nminute intervals for every sensor at every intersection in the city which works out to 2920 individual sensors across\n134 intersections in the CBD alone</p>\n<p>Our goal is to use this flow data to determine the presence of an incident on a section of road\nwithin a reasonable amount of time. Incidents are not restricted to vehicle accidents, they may also include:</p>\n<ul>\n<li>Breakdowns</li>\n<li>Spilled loads</li>\n<li>Natural disasters such as flooding and landslides</li>\n<li>Unscheduled maintenance</li>\n<li>Burst pipes </li>\n</ul>\n<p>It's imperative that the presence of these events is detected and responded to in a timely and appropriate manner \nby those working in a transport management center. Research has shown that the accuracy of these warnings is important\nas high false-positive rates result in fatigue and staff eventually ignoring alarms.</p>\n<p>In the field of automated incident detection (AID), the problem of detecting incidents in an arterial road networks\nis still an open problem. Current research is limited to supervised techniques that are typically run on\ndata collected in small scale traffic simulations that allow the researcher to easily optimise for 1 or 2 \nintersections and ignore the actual issue of scalability and the real-world application of their results.\nAdditionally, these simulations often provide a more fine grained level of data (eg. data is provided in 1 second\nintervals) than that of the real world data which typically has longer collection intervals. These simulations\nalso allow for ease of training since the simulation also provides the time, location and duration of any incident,\nsomething that is not easily obtained (although I have such data for this project and will use it for validation).</p>\n<h2>Detection</h2>\n<p>The use of HTM for this project was inspired by the <a href=\"https://github.com/nupic-community/htmengine-traffic-tutorial\" rel=\"nofollow\">htmengine-traffic-tutorial</a>, however, this project was limited to single input models \nusing <a href=\"https://github.com/numenta/numenta-apps/tree/master/htmengine\" rel=\"nofollow\">htmengine</a>, but I wanted to see how multi-input\nmodels would work for my dataset. So I based my code off of that in the \n<a href=\"https://github.com/numenta/nupic/tree/master/examples/opf/clients/hotgym/anomaly\" rel=\"nofollow\">hot gym anomaly tutorial</a>.</p>\n<p>This project  can run in one of two modes for detection, the first uses a single model per intersection, where each input is a single sensor. Each sensor looks at a particular\nlane and does not record turning movements, only vehicles passing a sensor. Intersections have at least 8 and at most 24 sensors. The large number of model inputs should be easily handled by the use of a purpose built server with 64GB  RAM and 15TB of RAID5 permanent storage.</p>\n<p>The second mode is a 1 model per sensor per intersection. Each model is run on its own subprocess to make best use of available parallel processing power. The results shown in the video use this mode of operation.</p>\n<p>The readings data can be smoothed using a mean filter, the window size of which can also be specified.</p>\n<h2>Dataset</h2>\n<p>The data for this project is supplied by the \n<a href=\"http://www.flinders.edu.au/science_engineering/csem/research/centres/tsc/\" rel=\"nofollow\">Flinders Transport Systems Centre</a> and is \nthus not available for public use. Currently, I have 7 years of historical data encompassing 3.5TB for the entire city\nof Adelaide. The data is stored in <em>mongodb</em> in the following format:</p>\n<pre class=\"language-nolang\"><code>{\n    \"readings\" : { \n        \"8\": 60, \n        \"16\": 32, \n        \"24\": 37, \n        \"32\": 25 , \n        \"40\": 11, \n        \"48\": 7, \n        \"56\": 8, \n         \"64\": 6,\n    },\n    \"site_no\" : \"46\",\n    \"datetime\" : ISODate(\"2010-01-29T09:15:00.000Z\")\n}\n</code></pre>\n<p>The readings are a dict that maps the sensor's ID to the vehicle count at that time. Sometimes, these sensors output\nan error value of 2046 or 2047 indicating physical damage or detector error respectively. In the application, these \nvalues are ignored and passed to the models as null values. Future work will seek to fill in these error gaps using \nsome form of prediction.</p>\n<h2>Usage</h2>\n<ol>\n<li>Make sure you've got a suitable version of python installed (preferably in a virtualenvironment) with nupic</li>\n<li>Import the SCATS data into your mongo instance\n\n<ul>\n<li>Make sure you've mongodb installed and in your path</li>\n<li>Use mongoimport to import the data files (contact me if you really want them since they're private):\nInvocation might look like\n<code>\nmongoimport --db htm_adelaide --collection readings --file readings.json\nmongoimport --db htm_adelaide --collection crashes --file crashes.json --numInsertionWorkers 3\nmongoimport --db htm_adelaide --collection locations --file locations.json\n</code></li>\n</ul></li>\n</ol>\n<ul>\n<li>If your instance is not on your machine, you'll need to provide <code>--host</code>, <code>--port</code>, <code>--username</code> and <code>-password</code>\nparameters</li>\n<li>For additional information refer to the documentation on <a href=\"https://docs.mongodb.org/v3.0/reference/program/mongoimport/\" rel=\"nofollow\">mongo import</a></li>\n<li>Once imported, make sure everything is indexed properly by running from the mongo client <code>mongo</code>:\n<code>\ndb.crashes.createIndex({datetime: 1})\ndb.crashes.createIndex({loc: \"2dsphere\"})\ndb.locations.createIndex({intersection_number: 1})\ndb.locations.createIndex({loc: \"2dsphere\"})\ndb.readings.createIndex({datetime: 1})\ndb.readings.createIndex({site_no: 1})\n</code>\n<ol>\n<li>Create a <code>connection.yaml</code> file in the root directory with:</li>\n</ol></li>\n<li>mongo_uri: (<code>string</code>) mongo connection URI</li>\n<li>mongo_database: (<code>string</code>) mongo database to use</li>\n<li>mongo_collection: (<code>string</code>) mongo collection to get vehicle flow data from</li>\n<li>GMAPS_API_KEY: (<code>string</code>) google maps api key for use with site</li>\n<li>MODEL_PARAMS_DIR: (<code>directory</code>) folder where model params will be stored</li>\n<li>MODEL_CACHE_DIR: (<code>directory</code>) folder where models are serialised to </li>\n<li>SWARM_CONFIGS_DIR: (<code>directory</code>) folder where swarm configurations are stored</li>\n<li>max_vehicles: (<code>int</code>) highest number of vehicles allowed per time period (200 is a good value)</li>\n</ul>\n<ol>\n<li>Run the model using <code>index.py</code> and evaluate anomaly results</li>\n</ol>\n<h5>Viewing the results</h5>\n<ol>\n<li>Navigate to <code>htm-site</code> folder </li>\n<li>Run <code>python setup.py develop</code></li>\n<li>Run the server with <code>pserve development.ini</code></li>\n<li>Access the site on <a href=\"http://127.0.0.1:8070\" rel=\"nofollow\">http://127.0.0.1:8070</a></li>\n<li>I only have data for the CBD area, so click on a marker and follow the link to see it's information</li>\n<li>To go to a specific intersection, use the url: <a href=\"http://127.0.0.1:8070/intersection/3083\" rel=\"nofollow\">http://127.0.0.1:8070/intersection/3083</a></li>\n<li>You should be able to see anomalies if they've been analysed, along with the raw readings. You can select which sensor\nyou want to show for by clicking the dropdown above the readings chart or using the link in the info. The anomaly chart\nshows green points as actual crashes. The orange points are times when the engine thinks an incident has occurred, each\n0.1 increment above zero for the orange points is 1 sensor in an \"accident\" state.</li>\n<li>To zoom in on any chart, just click and drag, to zoom out, double click anywhere on the chart.</li>\n<li>To widen the radius used in the crash search, click the radius button and select your range.</li>\n</ol>\n<h5>Don't feel like downloading 20MB pages?</h5>\n<p>If you're running nginx, you can use it take the output of the webapp, gzip and send it to you which should make\neach page a 1.2MB file. Follow the instructions in <a href=\"https://github.com/JonnoFTW/htm-models-adelaide/tree/master/htm-site\" rel=\"nofollow\">htm-site</a> for more.</p>\n<h5>Engine Arguments</h5>\n<ul>\n<li><code>--write-anomaly</code> : Write the anomaly score, predictions and anomaly likelihood back into the document</li>\n<li><code>--all</code>: Run all readings through models in parallel (can you specify a comma separated list of intersections with \n<code>--intersection</code> with this option, eg. <code>--all --intersection 3001,3002,3085</code>)</li>\n<li><code>--intersection</code>:  Name of the intersection(s) to process</li>\n<li><code>--incomplete</code>: Only process those readings without anomaly values</li>\n<li><code>--popular</code>: Show the most popular sensor for an intersection</li>\n<li><code>--cache-models</code>: Attempt to load models from cache and store them to disk</li>\n<li><code>--multi-model</code>: Use one model per sensor for the intersection (as opposed to making a single model that ues each\nsensor as an input). This mode will take longer and runs each model on a separate process.</li>\n<li><code>--smooth &lt;windowSize&gt;</code> use smoothing and specify the window size, 1 would indicate that we smooth over the current and previous record.</li>\n</ul>\n<h6>Examples</h6>\n<p>To run all the data for an intersection against a model do:</p>\n<p><code>./index.py --intersection 3083 --write-anomaly --multi-model</code></p>\n<p>To run all models in parallel do:</p>\n<p><code>./index.py --all --write-anomaly --multi-model</code></p>\n<h2>Results</h2>\n<p>Results will be stored in mongodb, alongside the readings for a particular intersection\nat a particular time, the prediction and anomaly score and anomaly likelihood will be saved.</p>\n<h2>TODO</h2>\n<ul>\n<li>Create a web service similar to the tutorial one to show a map of intersections and their anomaly states</li>\n<li>Create a warning system that sends an alarm when anomalous traffic is observed that may indicate an incident</li>\n<li>Have the data streamed in from the SCATS service in real time.</li>\n<li>Possibly link neighbouring models together, so that upstream and downstream flows are taken into account, although\nthe inputs of upstream/ downstream intersections can just be fed into the model.</li>\n<li>Allow different prediction frameworks to be use and cross evaluated with HTM. Candidate algorithms based on my\ninitial literature review of outlier predictors are:\n\n<ul>\n<li>BIRCH </li>\n<li>CluStream </li>\n<li>D-Stream</li>\n<li>DenStream</li>\n</ul></li>\n</ul>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/mongodb\">mongodb</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/JonnoFTW/htm-models-adelaide\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/JonnoFTW/htm-models-adelaide\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", ["I created the whole thing on my own as part of my PhD work. Most of the heavy lifting is provided by the nupic library from Numenta."]], ["ATAD", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/IKPbwldC88c?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>Who has never suffer any flight\u2019s delay? Currently there are thousands of flying airplanes all around the world. There are many airports, many companies, many different type of planes that makes really hard to find and explain anomalies in real-time. We believe that we can improve flying services for the companies and the users.</p>\n<h2>What it does</h2>\n<p>Uses flights information to detect geo-positional, speed and time anomalies and predict them.</p>\n<p>This first stage was focused on analyzing flights between LA and NY, assessing the flight path and to detect abnormal movements in flight in relation to its geo-position and heading.</p>\n<p>We got two different features.</p>\n<p>1) The first allows us to view the history of flights and find anomalous points detected by NUPIC</p>\n<p>2) But we also, we want to detect if any current flight is having an anomaly, so we can inform the airline about this situation. To do this, we have created a map having real time data, it\u2019ll notify the user if it find any anomaly.</p>\n<h2>How I built it</h2>\n<p>We built our app on top of MoClu (*), that way we can add hardware on demand to deal with tons of data for realtime flights.</p>\n<p>On the UI side we are using AngularJS that integrates with Lift 3 and Comet actors, a google maps angular implementation called angular-google-maps and D3 charts.</p>\n<p>The backend is built using 2 different web servers. </p>\n<p>One of them is used to connect to the models cluster, get and push new flights data coming from external sources also it saves results into MongoDB.</p>\n<p>The second web server is used to serve this data to the client. Both web servers can be scaled horizontally.</p>\n<h2>Challenges I ran into</h2>\n<p>One problem we noticed is that scalability for this kind of system is crutial.</p>\n<p>We detected many anomalies near the airports because we didn't have the enough sample size to learn, this leads to false positives.</p>\n<h2>Accomplishments that I'm proud of</h2>\n<p>(*) HTM-MoClu: by definition HTM-MoClu is short for Hierarchical Temporal Memory Models Cluster. Htm-MoClu provides a platform similar to HtmEngine for htm.java applications, and has the ability to scale horizontally using multiple servers.</p>\n<h2>What I learned</h2>\n<p>HTM, Sensor configuration, flight data, Clusters configuration.</p>\n<h2>What's next for Air traffic anomaly detector</h2>\n<p>A lot of value can be delivered by ATAD in a short-term future, such as:</p>\n<ul>\n<li><p>Give the possibility to a person who is about to buy a ticket to select a flight not only based on costs and benefits but also for the possibility of having a fault, making the travel experience better.</p></li>\n<li><p>Find which airports have more anomalies than others, in order to provide this information for later use by airlines or passagers.</p></li>\n<li><p>Report on the number of anomalies by flight to assess their personal onboard.</p></li>\n<li><p>Add weather information to understand it impact and to help plan situations where airports are closed to prevent early collapse secondary airport facilities like hotels.</p></li>\n<li><p>Analyze routes and airports can enable airlines to enhance their routes management in order to reduce costs generated by anomalies.</p></li>\n</ul>\n<p>We believe this information is useful for all the stakeholders, but primarily for the passenger, who will receive a better travel experience.</p>\n<p><a href=\"https://github.com/antidata/ATAD\" rel=\"nofollow\">https://github.com/antidata/ATAD</a></p>\n<p><a href=\"https://github.com/antidata/htm-moclu\" rel=\"nofollow\">https://github.com/antidata/htm-moclu</a></p>\n<p><a href=\"https://github.com/numenta/htm.java\" rel=\"nofollow\">https://github.com/numenta/htm.java</a></p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/java\">java</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/mongodb\">mongodb</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/angular-js\">angular.js</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/google-maps\">google-maps</a></span></li><li><span class=\"cp-tag\">api</span></li><li><span class=\"cp-tag\">htm.java</span></li><li><span class=\"cp-tag\">htm-moclu</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/scala\">scala</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/antidata/ATAD\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/antidata/ATAD\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", ["", ""]], ["ECG + HTM", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/VOczYasynUU?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"ECG + HTM \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/307/092/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"ECG + HTM \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/308/355/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h1>ECG + HTM</h1>\n<p>ECG Anomaly Detection System using HTM</p>\n<h2>Abstruct</h2>\n<p>In this projects, We build Electrocardiogram(ECG)\nanomaly detection system using HTM(NuPIC).\nThis system will detect Palpitation, Arrhythmia and Heart Rate anomaly.</p>\n<h2>System Structure and Usage</h2>\n<p>There are about three parts of the projects.</p>\n<ul>\n<li>Data Collector</li>\n<li>FFT Converter</li>\n<li>Anomaly Detector</li>\n</ul>\n<h3>Data Collector</h3>\n<p>It's not difficult to make your own ECG device.\nIf you are not interested in collecting data by yourself,\nYou can skip this part and use data in <code>data</code> directory.</p>\n<p>We use</p>\n<ul>\n<li><a href=\"https://www.sparkfun.com/products/11114\" rel=\"nofollow\">Arduino Pro mini</a></li>\n<li><a href=\"https://www.sparkfun.com/products/12650\" rel=\"nofollow\">Sparkfun Ad8232</a></li>\n</ul>\n<p><img alt=\"device\" data-canonical-url=\"https://cloud.githubusercontent.com/assets/478824/11051785/5fb18f74-8795-11e5-940c-7164d8b0ca75.jpg\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--T1fLazNg--/https://cloud.githubusercontent.com/assets/478824/11051785/5fb18f74-8795-11e5-940c-7164d8b0ca75.jpg\"/></p>\n<p>Sparkfun's <a href=\"https://learn.sparkfun.com/tutorials/ad8232-heart-rate-monitor-hookup-guide\" rel=\"nofollow\">tutorial</a> is very friendly.\nYou can also use Sparkfun's <a href=\"https://github.com/sparkfun/AD8232_Heart_Rate_Monitor\" rel=\"nofollow\">Github Repository</a> to get simple visualization of ECG Data. Visualization output is like this <a href=\"https://www.youtube.com/watch?v=yTcbTTxECTU\" rel=\"nofollow\">video</a>.</p>\n<p>Next, Collect ECG Data through the script.</p>\n<pre class=\"language-nolang\"><code>$ python src/take_data.py &gt; data/foobar.csv\n</code></pre>\n<p>Collected Data have this format.</p>\n<pre class=\"language-ecg.csv\"><code>2015-10-17 21:05:10.078937,483\n2015-10-17 21:05:10.094542,481\n2015-10-17 21:05:10.094833,480\n2015-10-17 21:05:10.094949,485\n2015-10-17 21:05:10.095044,492\n2015-10-17 21:05:10.110693,501\n</code></pre>\n<p>If you want to visualize collected data, You can use Gnuplot.</p>\n<pre class=\"language-nolang\"><code>$ gnuplot\nset datafile separator \",\"\nplot \"&lt; head -1000 data/foobar.csv\" using 2 with line\n</code></pre>\n<p><img alt=\"2015-11-09 21 48 35\" data-canonical-url=\"https://cloud.githubusercontent.com/assets/478824/11034054/ba0744ec-872b-11e5-8e49-d97acbe44966.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--49ITa9Bw--/https://cloud.githubusercontent.com/assets/478824/11034054/ba0744ec-872b-11e5-8e49-d97acbe44966.png\"/></p>\n<h3>FFT Converter</h3>\n<p>Before detecting anomalous part of the ECG data, \nWe use a signal processing technique, FFT(Fast Fourier Transform).\nFFT can be used to extract charactaristics of data sequence.\n<code>Numpy</code> library contain FFT, and we use that.</p>\n<p>See example for using FFT Converter with ECG data collected by <code>take_data.py</code>.\nYou can also use the preset data of the repository.\nFFT converter can use like this.</p>\n<pre class=\"language-nolang\"><code>$ python src/fft_converter.py --target healthy_person1\n</code></pre><pre class=\"language-output.csv\"><code>2015-10-17 21:05:12.685818,11.808565811567473,...,10.957521665215634\n2015-10-17 21:05:12.701433,11.808734646395951,...,7.7589930598122354\n...\n2015-10-17 21:05:57.033917,11.821344935267192,...,8.5655396209023618\n</code></pre>\n<p>You can use <code>--target</code> option to specify the target file's name.\nDont's forget to remove <code>.csv</code> string from file name.</p>\n<p>FFT Converted data are can be visualized using Gnuplot.</p>\n<p><img alt=\"2015-11-07 18 54 14\" data-canonical-url=\"https://cloud.githubusercontent.com/assets/478824/11034302/ea8045ae-872d-11e5-98dd-4ec855fc76ab.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--K84r-s1w--/https://cloud.githubusercontent.com/assets/478824/11034302/ea8045ae-872d-11e5-98dd-4ec855fc76ab.png\"/></p>\n<p>Non uniform parts are corredpond to the anomalous of ECG data.</p>\n<h3>Anomaly Detection</h3>\n<p>We use anomaly detection using <code>vector_anomaly.py</code> Script.\nYou shoud use FFT Converted data.</p>\n<pre class=\"language-nolang\"><code>$ python src/vector_anomaly.py \n</code></pre>\n<p>This is the visualization of the output.</p>\n<p><img alt=\"d2378b575a8f02188069ef80a08ae6fd 1\" data-canonical-url=\"https://cloud.githubusercontent.com/assets/478824/11034523/85169d4c-872f-11e5-8ed4-55964ef5c7f0.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--1zPSzI73--/https://cloud.githubusercontent.com/assets/478824/11034523/85169d4c-872f-11e5-8ed4-55964ef5c7f0.png\"/></p>\n<h2>Data</h2>\n<p>This repository include some helathy and abnormal ECG data.\nThese data are in <code>data</code> directory.</p>\n<h3>Nomral ECG data</h3>\n<ul>\n<li><code>data/healthy_person1.csv</code></li>\n<li><code>data/healthy_person2.csv</code></li>\n<li><code>data/healthy_person3.csv</code></li>\n<li><code>data/healthy_person4.csv</code></li>\n</ul>\n<h3>Abnormal ECG data</h3>\n<ul>\n<li><code>data/disease_person1.csv</code>\n<ul>\n<li>This data contain big anomalous part.</li>\n</ul></li>\n<li><code>data/disease_person2.csv</code>\n<ul>\n<li>This data contain small anomalous part.</li>\n</ul></li>\n<li><code>data/disease_person3.csv</code>\n<ul>\n<li>This data is chronically abnormal in QRS wave.</li>\n</ul></li>\n</ul>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/arduino\">arduino</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">ecg</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/iizukak/ecg-htm\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/iizukak/ecg-htm\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["ComportexViz, but for NuPIC", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/rEQ2XVOnhDw?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"ComportexViz, but for NuPIC \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/452/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>I wanted to show that this is possible and practical.</p>\n<h2>What it does</h2>\n<p>It's a way to see your HTM run. Take a look at the screencast!</p>\n<h2>How I built it</h2>\n<p>This has been low-hanging fruit for a few months, ever since I made ComportexViz work with remote HTMs, e.g. Comportex on the JVM. ComportexViz just receives instructions for what to draw, so we could totally swap a Python NuPIC server in place of the Clojure Comportex server. You can read my high-level ComportexViz design <a href=\"http://mrcslws.com/blocks/2015/07/30/data-flow-visualizing-big-remote-things-part-2.html\" rel=\"nofollow\">here</a>.</p>\n<h2>Accomplishments that I'm proud of</h2>\n<p>It took 2 days to get the proof-of-concept working, synapses and all. I finished the screencast 6 days after starting this project. I think this helps make my case that this is practical.</p>\n<p>I'm glad I found a way to make it fast. The way NuPIC works, I wasn't sure I'd find a way. The solution: redesign ComportexViz a little bit, so that toggling synapse-saving is part of using it.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">clojurescript</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/mrcslws/comportexviz-nupic\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/mrcslws/comportexviz-nupic\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["CloudSonar", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/9OKGz4p-P6g?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>The critical event any IT service provider cares is a service outage(e.g. HTTP 5xx response). But there are just too many variables. uptime, Java gc counts/time, CPU, I/O util, swap memory usage, etc.</p>\n<p>Whenever you try to detect a service outage before it happens, you get screwed up by those countless variables.</p>\n<p>One day, I noticed Apache Cassandra uses a very simple metrics to detect a node failure, which is based on the following theory.</p>\n<p><a href=\"http://www.jaist.ac.jp/%7Edefago/files/pdf/IS_RR_2004_010.pdf\" rel=\"nofollow\">http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf</a></p>\n<p>This inspired me to try HTM against simple PING response times to predict possible high load that could generate an error.</p>\n<h2>What it does</h2>\n<p>It polls a given set of nodes by PING periodically. Then, record its response times, and which are fed to PhiFailureDetector and HTMAnomalyDetector to detect an important event to watch out.</p>\n<p>Please refer to <a href=\"https://github.com/ggsato/CloudSonar#concept\" rel=\"nofollow\">Concept</a> on my project for details.</p>\n<h3>Case Study</h3>\n<p>The case study I have investigated was done on a 6 nodes Cloudian HyperStore(S3 object storage) cluster. You can simply think of it as a distributed file system with a web interface. All the HTTP requests were routed to cloudian-node1, then distributed among 6 storage services. </p>\n<p>The traffic pattern I used was a constantly high traffic for this cluster, which would produce an error if some more requests had been added.</p>\n<p><img alt=\"traffic pattern\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/traffic_pattern.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--2pORnr6V--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/traffic_pattern.png\"/></p>\n<p>To make it overloaded, a temporal random traffic surge was added every hour. Then, as expected, 6 errors were observed as follows.</p>\n<p><img alt=\"http statuses\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/http_responses.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--Y55MKC9X--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/http_responses.png\"/></p>\n<p>Now, the first question is if this tool could have provided a useful information based on anomaly score by HTM before they happened.</p>\n<p>The followings are examples against node1 taken on node3.</p>\n<p>HTM inputs, log10 of response time in micro seconds, looked like this.</p>\n<p><img alt=\"log10 of response time in micro seconds\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/log10_response_timeseries.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--y6nI18Zs--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/log10_response_timeseries.png\"/></p>\n<p>This looks there is no direct indication of such an error. For example, around 6:50, there were 4 503 errors. But no particular spike there. There could be a hidden pattern, but may be not. Let's see.</p>\n<p>And this is the distribution. 2.5 is around 300 micro seconds.</p>\n<p><img alt=\"the distribution of log10 response time in micro seconds\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/log10_response_distribution.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--WoxK0u2e--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/log10_response_distribution.png\"/></p>\n<p>PhiFailureDetector shows a server health. It is below 1.0, if it is fine. The lower, the better. You can set a horizontal line(threshold) to identify a bad node.</p>\n<p>Here, as you can see, there are so many high values over 1.0. Some spikes are even beyond 10(0.0000001%). This indicates that the server was under high load.</p>\n<p>A PHI value is a good indication of server health, but simply lowering a threshold doesn't really help. For example, if you would set 2.0, the first alarm could have been given around 22:10, followed by many more alerts. You may try 5.0 to avoid too many alarms. But you still have no idea if this is OK or not. </p>\n<p><img alt=\"phi time series\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/phi_timeseries.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--ZoD3Yi5v--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/phi_timeseries.png\"/></p>\n<p>HTMAnomalyDetector allows you to see a vertical line instead of a horizontal line(threshold), which indicates an anomaly, the time when unexpected pattern was observed against its prediction(max in the next 30 seconds).</p>\n<p>As you can see, HTM detected whenever a pattern has changed.</p>\n<p><img alt=\"anomaly detector\" data-canonical-url=\"https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/anomaly_max30.png\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--EmvBuWYR--/https://raw.githubusercontent.com/ggsato/CloudSonar/master/resources/images/anomaly_max30.png\"/></p>\n<h3>Conclusion</h3>\n<p>Cloud Sonar is not an oracle, so can not tell when an error could happen. But Cloud Sonar is confirmed that it can give an anomaly whenever a pattern changes.</p>\n<p>If you look back a pattern when your server got overloaded, then you'll see the first point that became higher than its usual pattern. And it must be the first possible point you could be notified.</p>\n<p>So, the best way to deal with an unexpected event is to know as soon as possible when a change is observed. And it is what Cloud Sonar can provide.</p>\n<h2>How I built it</h2>\n<p>Using HTM.java, and Swarming to find optimal configurations.</p>\n<h2>Challenges I ran into</h2>\n<ul>\n<li><p>HTM parameter tunings.<br/>\n=&gt; Let Swarming find<br/>\n==&gt; Takes long...  </p></li>\n<li><p>HTM input scale.</p></li>\n</ul>\n<h2>Accomplishments that I'm proud of</h2>\n<p>A very simple method to monitor a server health, and detect an anomaly.</p>\n<h2>What I learned</h2>\n<p>I have tried to collect more and more features. But an important simple value contains so many information. The hardest part is how to find it, and extract valuable information out of it.</p>\n<h2>What's next for CloudSonar</h2>\n<ol>\n<li>more patterns like daily/weekly/monthly/holiday/seasonal<br/>\n==&gt; the result will be presented at Data Tech conference in Dec. at Tokyo</li>\n<li>serialization (contribution to htm.java)</li>\n<li>flume/fluentd appender to upload csv files to S3 storage for analytics</li>\n</ol>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/java\">java</a></span></li><li><span class=\"cp-tag\">htm.java</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/ggsato/CloudSonar\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/ggsato/CloudSonar\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["Fitness Fortuna", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/bH_V_IcELX8?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Fitness Fortuna \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/802/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"Fitness Fortuna \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/805/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Fitness Fortuna</h2>\n<p>The user plays a game with <strong>Fitness Fortuna</strong>, in which the user has to beat the step count value predicted by the HTM model within the next time-step. If the user beats the model's predicted step count by exercising/walking/working out within the next time step, rewards (currently points) are given for the user's accomplishments. The user's health and fitness levels improve as they beat the step-count predictions.</p>\n<h2>Inspiration</h2>\n<p>It has been only 3 weeks since we started learning about CLA (HTM) and NuPIC. We were instantly intrigued by the capabilities offered by this new learning algorithm modeled after the human Neocortex. </p>\n<p>We wanted to use this framework to make a consumer facing application that will be useful throughout the day with minimal user interaction. We quickly learned that temporal data with high velocity is very suitable for HTM learning and hence chose a wearable (Apple Watch) to get Step count data, use it to make predictions about user's activity patterns. </p>\n<p>After a bit of brainstorming, we decided to make the user play a game with the HTM algorithm. By participating in the game, the user is providing active feedback to the HTM about stepcount and activity pattern, thereby making the prediction more accurate over time. </p>\n<h2>What it does</h2>\n<p>This is an iPhone app that collects real-time step count data from HealthKit (Apple Watch+iPhone) and feeds it to a server running HTM prediction and anomaly detection using NuPIC. The server return a prediction for the number of steps in the next time interval, back to the app. </p>\n<h2>How I built it</h2>\n<p><strong>Server:</strong> <a href=\"https://github.com/numenta/nupic\" rel=\"nofollow\">NuPIC</a>, Python\n <strong>iPhone:</strong> Swift</p>\n<p><strong>Resources:</strong> CLA(<a href=\"https://github.com/numenta/nupic/wiki/Hierarchical-Temporal-Memory-Theory\" rel=\"nofollow\">HTM</a>) <a href=\"http://numenta.com/learn/hierarchical-temporal-memory-white-paper.html\" rel=\"nofollow\">whitepaper</a>, Jeff Hawkins's videos, Matt Taylor's NuPIC tutorials, Dr. Subbutai Ahmad's lectures, <a href=\"https://www.youtube.com/user/OfficialNumenta\" rel=\"nofollow\">NuPIC community videos</a></p>\n<h2>What's next for Fitness Fortuna</h2>\n<ul>\n<li>Combine multiple data source from wearables</li>\n<li>Make effective use of anomaly detection inference</li>\n<li>Natural language user interface to humanize the HTM algorithm</li>\n</ul>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/swift\">swift</a></span></li><li><span class=\"cp-tag\">apple-watch</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/iyergkris/step-oracle\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/iyergkris/step-oracle\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", ["", ""]], ["Clairvaux", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/4C5389s3ckQ?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Clairvaux \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/313/958/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Synopsis</h2>\n<p>This project aims to predict and visualize armed conflict data for African states. Realtime data can be obtained from <a href=\"http://www.acleddata.com\" rel=\"nofollow\">ACLED (Armed Conflict Location and Event Data Project)</a>. Prediction module uses Numenta's <a href=\"http://numenta.org/\" rel=\"nofollow\">Hierarchical Temporal Memory (HTM)</a> model, which is based on a brain-inspired theory of neuroscience.</p>\n<p>A <a href=\"http://bost.ocks.org/mike/miserables/\" rel=\"nofollow\">co-occurence matrix</a> based on d3.js is used for predictive visualization. This type of matrix is normally used for text-mining. For this project, rows correspond to actual events while columns are predicted events. Darker cells indicate more frequent co-occurrence of actual and predicted events.</p>\n<h2>Motivation</h2>\n<p>The primary motivation is to learn about Numenta's HTM framework. A secondary motivation is to explore techniques for categorical prediction and predictive visualization.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/java\">java</a></span></li><li><span class=\"cp-tag\">htm.java</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/d3-js\">d3.js</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/bootstrap\">bootstrap</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/heroku\">heroku</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/datjandra/Clairvaux\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/datjandra/Clairvaux\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n<li><a href=\"http://clairvaux.herokuapp.com\" rel=\"nofollow\" target=\"_blank\" title=\"http://clairvaux.herokuapp.com\">\n<i class=\"ss-icon ss-link\"></i>\n<span>clairvaux.herokuapp.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["AI-909", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/2y4549AjgEE?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"AI-909 \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/317/403/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>The AI-909 is inspired by the idea of training a computer to write music by learning from examples from a human operator.</p>\n<h2>What it does</h2>\n<p>The AI-909 combines the basic functionality of a drum machine with machine intelligence to learn and produce its own drum sequences. After inputting example sequences, the application learns to generate its own novel drum patterns or create a variation of an input sequence.</p>\n<h2>How I built it</h2>\n<p>I used the HTM.java port of NuPIC's core algorithms to learn sequences and produce new ones. The frontend is handled in the browser in JavaScript and the two parts communicate over a REST API handled by Spring.</p>\n<h2>Challenges I ran into</h2>\n<p>The hardest parts were coming up with a logical encoding for patterns and tuning the HTM parameters to produce sensible output.</p>\n<h2>Accomplishments that I'm proud of</h2>\n<p>As far as I know, I'm the first person to train the HTM to write breakbeats, so there's that.</p>\n<h2>What I learned</h2>\n<p>This was the first project I ever built with the HTM, so...a lot.</p>\n<h2>What's next for AI-909</h2>\n<p>Adding additional drum channels, handling of unusual time signatures, velocities, effects, a better encoding (by basing the bits of the SDR on the frequency ranges of each individual drum). Adding melodies and writing entire songs would be long-term goals.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag\">htm.java</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/javascript\">javascript</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/java\">java</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/jquery\">jquery</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/spring\">spring</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/create-js\">create.js</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/TaylorPeer/AI-909\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/TaylorPeer/AI-909\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["Semantic Anomaly Detection", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/zNyNTbig7yw?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Semantic Anomaly Detection \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/315/829/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>The \"Breaking News\" hack from the 2015 Numenta Spring Hackathon </p>\n<h2>What it does</h2>\n<p>The system monitors semantic changes in a text stream, in this case in the Twitter feeds of several US Presidential candidates. The application displays anomaly scores in the stream calculated by the HTM, giving the user an indication of unusual topic changes detected in the stream. The user can then inspect the actual text in the stream using the UI to investigate the anomalies found.</p>\n<h2>How we built it</h2>\n<p>We used the Twitter API to retrieve Tweets for six top presidential candidates. After aggregating the Tweets by day, we create a semantic SDR representation for each day's Tweets using the Cortical.io API. These SDRs are then input into an HTM for each candidate, which learns the semantic patterns contained in candidate's posts and computes anomaly scores. We built a frontend in JavaScript that communicates with the HTM via a REST API implemented in Python to display the data to the user in an interactive web application.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/javascript\">javascript</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"http://www.cortical.io/demos/semantic-anomaly-detection/\" rel=\"nofollow\" target=\"_blank\" title=\"http://www.cortical.io/demos/semantic-anomaly-detection/\">\n<i class=\"ss-icon ss-link\"></i>\n<span>www.cortical.io</span>\n</a></li>\n</ul>\n</nav>\n</div>", ["", "", ""]], ["Chatanomaly", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/qBbPecg6u9g?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Chatanomaly \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/316/349/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"Chatanomaly \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/316/350/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>I wanted to analyze a long-running group conversation on Google Hangouts that I'm a member of. It would be see where the message activity was anomalous, and be notified automatically when it's worth checking the conversation.</p>\n<h2>What it does</h2>\n<p>It will feed the number of messages per hour (or some other aggregation interval) in the conversation over time to NuPIC. NuPIC will analyze the data stream for anomalous events, and produce a graph of the anomalies in the data over time.</p>\n<h2>Other applications</h2>\n<p>This kind of project could be used to monitor any online conversation between people (like on news sites, communities, etc.), to automatically generate notifications when the conversation is anomalous and thus interesting to check.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">nupic</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/chetan51/nupic.hangouts\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/chetan51/nupic.hangouts\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["Column Swarm Reinforcement Learning (CSRL)", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/xyrB1FvqGdc?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Column Swarm Reinforcement Learning (CSRL) \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/305/220/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"Column Swarm Reinforcement Learning (CSRL) \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/305/221/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>What it does</h2>\n<p>Column Swarm Reinforcement Learning (CSRL) is a swarm intelligence model composed of a bi-directional hierarchy of \"swarmling\"-minicolumns developed based on HTM technology. Each column can solve many simple tasks on its own, but together they can solve large-scale problems.</p>\n<p>CSRL is on other words a lot of little reinforcement learners that work together to create one big reinforcement learner, where the resulting hierarchical model looks astoundingly like HTM.</p>\n<h2>How I built it</h2>\n<p>I came up with the idea of using a swarm intelligence model with HTM after seeing Jeff's 6-layer model of the neocortex. I thought of ways that the construction of such a hierarchy could be done automatically. I had previously had some success using swarms of simpler learning automata, and with the development of SDRRL (an ultra-efficient \"swarmling\") and its similarity to cortical minicolumns used in HTM I decided to make a fully blown hierarchy with them.</p>\n<p>I wrote it in C++, first on the CPU. I will move it to the GPU using OpenCL soon.</p>\n<h2>Details</h2>\n<p>CSRL is composed of a lot of small reinforcement learners that work together. I wrote a tutorial for a single on of those reinforcement learners (called SDRRL, sparse distributed representation reifnorcement learning). At least, this is what it will be composed of in the future; currently it is composed of simple OLPOMDP learners.</p>\n<p>Here is a tutorial on how to create SDRRL: <a href=\"http://twistedkeyboardsoftware.com/?p=90\" rel=\"nofollow\">link</a>\nA tutorial on the full swarm will come soon.</p>\n<p>These SDRRL units are organized into a hierarchy, where the actions of a unit are fed in as inputs to other units. Each unit optimizes locally, but the end result is that the whole swarm optimizes globally as well.</p>\n<h2>Challenges I ran into</h2>\n<p>Optimizing SDRRL. SDRRL is insanely fast be default, but I need to run potentially <em>millions</em> of SDRRL swarmlings at once. So I came up with several mechanisms to exploit the SDRRL sparsity to reduce computational costs.</p>\n<h2>What's next for Column Swarm Reinforcement Learning</h2>\n<p>GPU version, more demos. Performance improvements. Integrate SDRRL into CSRL (Instead of OLPOMDP).</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/c--3\">c++</a></span></li><li><span class=\"cp-tag\">sfml</span></li><li><span class=\"cp-tag\">opencl</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/222464/BIDInet\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/222464/BIDInet\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["Brain Squared", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/CXXGO88roWQ?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Brain Squared \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/301/312/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<p>Disclaimer: This project is not eligible for prizes. Just for fun!</p>\n<h2>What it does</h2>\n<p>Collect EEG data (i.e. brainwaves) and classify your mental states. One common mental state that is often classified is motor imagery, that is to say imagined motor movements (e.g moving your hand left or right).  By classifying data from the motor cortex we can extract controls to interact with the physical/digital world.</p>\n<h2>Building blocks</h2>\n<p><a href=\"http://github.com/cloudbrain\" rel=\"nofollow\">Cloudbrain</a> for the EEG data collection. NuPIC for the EEG data classification. <a href=\"http://openbci.com\" rel=\"nofollow\">OpenBCI</a> for the EEG data acquisition.</p>\n<h2>Inspiration</h2>\n<p>We built a <a href=\"http://www.explorecogtech.com/projects.html#MIM\" rel=\"nofollow\">similar project for the Exploratorium of SF</a> but not with the HTM. \nWe learned from the Exploratorium exhibit that neurofeedback is going to be key for a good user experience in this project. And of course a quality classifier for the temporal data :-)</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag\">cloudbrain</span></li><li><span class=\"cp-tag\">openbci</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/CloudbrainLabs/htm-challenge\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/CloudbrainLabs/htm-challenge\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n<li><a href=\"http://cloudbrain.rocks/#/brainsquared\" rel=\"nofollow\" target=\"_blank\" title=\"http://cloudbrain.rocks/#/brainsquared\">\n<i class=\"ss-icon ss-link\"></i>\n<span>cloudbrain.rocks</span>\n</a></li>\n</ul>\n</nav>\n</div>", ["Training/UX", "", "", "", ""]], ["Hard Drive Lifeguard", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/0DhYOIwmCkY?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Hard Drive Lifeguard \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/297/816/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>Software engineers should spend more time towards R&amp;D for better future. It could be healthcare or any other stream. As the need grows so does the software applications, data and infrastructure. I see more and more time and effort is spent on maintenance, handling operational cases. With facility of Cloud Infrastructure, datascience and techniques like HTM its best time to automate these processes. Thereby allowing engineers to spend more quality time thinking for nextgen.</p>\n<h2>What it does</h2>\n<p>Predicts hard drive failures using TemporalAnomaly Model</p>\n<h2>How I built it</h2>\n<p>Data Ingestion is done using collectors which read SMART data attributes from clusters<br/>\nSMART Attributes are read at frequency of 2 hours and sent to common database<br/>\nAdapters feed data from this common datastore to Model (good and bad) to get anomaly score<br/>\nAnomaly score is used to classify data<br/>\nFinally the classification is analyzed against actual class</p>\n<h2>Challenges I ran into</h2>\n<p>Getting right feature vector<br/>\nUnderstanding temporal nature of Harddrive data<br/>\nChoosing right modeling technique<br/>\nPerforming binary classification<br/></p>\n<h2>Accomplishments that I'm proud of</h2>\n<p>I always wanted to start and attempt but couldn't make time for same. Finally through this hackathon i am working on my favorite theory of Machine Intelligence and applying it to solve real problem i see today.</p>\n<h2>What I learned</h2>\n<p>Lots of it, Nupic modeling techniques, how important it is to understand data and fetch right feature vector.\nPython.</p>\n<h2>What's next for htm-drivefailures</h2>\n<p>I am presenting this at my work and will continue my efforts with help of community to further test it with real time data and take it from gamma to prod state in future.</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag\">nupic</span></li></ul>\n</div>\n<nav class=\"app-links section\">\n<h2>Try it out</h2>\n<ul class=\"no-bullet\" data-role=\"software-urls\">\n<li><a href=\"https://github.com/badlogicmanpreet/htm-drivefailures.git\" rel=\"nofollow\" target=\"_blank\" title=\"https://github.com/badlogicmanpreet/htm-drivefailures.git\">\n<i class=\"ss-icon ss-link\"></i>\n<span>github.com</span>\n</a></li>\n</ul>\n</nav>\n</div>", [""]], ["Knowledge Graph with HTMs", "<div class=\"large-9 columns\" id=\"app-details-left\">\n<div id=\"gallery\">\n<ul class=\"no-bullet\" data-options=\"animation_speed:0;slide_number:false;timer:false\" data-orbit=\"true\">\n<li>\n<div class=\"flex-video\">\n<iframe allowfullscreen=\"allowfullscreen\" allowscriptaccess=\"always\" class=\"video-embed\" frameborder=\"0\" height=\"375\" mode=\"transparent\" src=\"https://www.youtube.com/embed/PfOxeDz5xrg?enablejsapi=1&amp;hl=en_US&amp;rel=0&amp;version=3&amp;wmode=transparent\" type=\"text/html\" webkitallowfullscreen=\"true\" width=\"615\" wmode=\"transparent\"></iframe>\n</div>\n</li>\n<li class=\"text-center\">\n<img alt=\"Knowledge Graph with HTMs \u2013 screenshot 1\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/320/682/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"Knowledge Graph with HTMs \u2013 screenshot 2\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/320/684/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li> <li class=\"text-center\">\n<img alt=\"Knowledge Graph with HTMs \u2013 screenshot 3\" class=\"software_photo_image image-replacement\" src=\"//challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/320/683/datas/gallery.jpg\"/>\n<p>\n<i></i>\n</p>\n</li>\n</ul> </div>\n<div>\n<h2>Inspiration</h2>\n<p>I am working on a intelligent bots that will help people do more through natural language. Imagine a world where\nyou can chat with an AMC bot and book your movies or a 49ers bot to learn about the latest game. These bots\nwith need a corpus of knowledge to make sense of what the user is saying. HTMs seem like a natural fit due to\ntheir strong biological concepts and the highly connected nature of the HTM memory.  </p>\n<h2>What it does</h2>\n<p>Meet <img alt=\"Hollybot\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mRFVzNWtqbXNXeHc\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--pcKIJELX--/https://googledrive.com/host/0B65T0AsIek5mRFVzNWtqbXNXeHc\" title=\"This is Hollybot\"/>\nHollybot is a bot, he lives in Slack [the popular messaging platform] and your phone. Hollybot knows about movies and uses his knowledge to help you with questions you have about movies. A user can ask about a movie, about a genre or anything in the world of movies. As long as Hollybot has seen it before in its corpus it will retrieve not just what you asked for but a knowledge graph of all other concepts that are related to that word .</p>\n<p><strong>A few sample interactions with Holly Bot:</strong></p>\n<p>User Text: \"#hollybot help\"\nHollyBot response:\n<img alt=\"Hollybot Help\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mSGNoVW80aGcwaGs\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--Qxzyz4FH--/https://googledrive.com/host/0B65T0AsIek5mSGNoVW80aGcwaGs\" title=\"Help Response\"/></p>\n<p>User Text: \"#hollybot Toy Story\"\nHollyBot response:\n<img alt=\"Hollybot Response\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mNlRDVXNBLVpFbnM\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--U1qXRDAo--/https://googledrive.com/host/0B65T0AsIek5mNlRDVXNBLVpFbnM\" title=\"Response\"/>\nThe top section of movie related information is retrieved from an open movie database in realtime\nThe bottom section , the knowledge graph is retrieved from a HTM server.</p>\n<h2>Mobile Interface</h2>\n<p>Hollybot is available on you mobile phone. See Hollybot in action here. \nRequires slack mobile app. Supported on IOS and Android phones.</p>\n<h2><img alt=\"Hollybot\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5maXcyTzQ4WVFyOVE\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--v58yHQmv--/https://googledrive.com/host/0B65T0AsIek5maXcyTzQ4WVFyOVE\" title=\"This is Hollybot\"/></h2>\n<p><img alt=\"Hollybot\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mbFdKR256ZGswYnc\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--GYhRwJAz--/https://googledrive.com/host/0B65T0AsIek5mbFdKR256ZGswYnc\" title=\"This is Hollybot\"/></p>\n<h2>How I built it</h2>\n<p><img alt=\"Hollybot\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mcU5LNU9zczJPbHc\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--7795q1W6--/https://googledrive.com/host/0B65T0AsIek5mcU5LNU9zczJPbHc\" title=\"This is Hollybot\"/></p>\n<p>** Client Layer **\nThis is a slack client, It is hosted on a server and listens to chat messages in the #general channel of Slack. It looks for certain keywords being spoken. When it finds keywords it is looking for it takes an action</p>\n<p>*<em>AI Layer - HTMS *</em>\nFor this layer I have built and HTM server, the server is always on an allows for state being maintained in between interactions from the client layer. There is also a HTM client , that connects with the HTM server . This way the client may start and stop any number of times while the server in always on. The server is has a model defined via xml. This specifies the design of the HTM model. It has encoder, spatial pooler and temporal memory . There is also a new generic encoder which was built. The generic encoder is able to extract topological information from text. This allows for a robust representation of natural language which can be high in noise and error rates. </p>\n<p>Data is fed in the form of CSV files, The model trains itself on each line of data in the CSV file and tries to make synapses with information it seen in each frame of data represented in a line. All of this data is stored in the HTM model which maintains the state in the form of synaptic connections between columns of cells in the HTM memory.\nBelow is a picture of the training process. See the Raw value, Encoded value, and the predictions .</p>\n<p><img alt=\"Training Process\" data-canonical-url=\"https://googledrive.com/host/0B65T0AsIek5mWm1uczFIZFNOZEE\" src=\"https://res.cloudinary.com/devpost/image/fetch/s--MA3eNWmT--/https://googledrive.com/host/0B65T0AsIek5mWm1uczFIZFNOZEE\" title=\"Training Process\"/></p>\n<h2>Technology Stack</h2>\n<p>Nupic, Python, Django , Custom Encoder, Json etc</p>\n<p>*<em>New Resources Developed *</em></p>\n<ul>\n<li>New encoder that captures information about textual data</li>\n<li>Nupic server and client that can maintain state in between calls from the user</li>\n<li>Hollybot for interaction and visualize the knowledge graph</li>\n<li>Integration with data from IMDB and OMDB about movies and movie related information</li>\n</ul>\n<h2>Challenges I ran into</h2>\n<p>While low level concepts are being captured and represented , I see that I may need a hierarchy of layers to capture higher level patterns. This is going to part of the next phase of this project</p>\n<h2>Accomplishments that I'm proud of</h2>\n<p>Being able to complete the project in time. Many of the concepts I am working on here are quite early stage. This required a lot of experimentation and discovery. </p>\n<h2>What I learned</h2>\n<p>The HTM theory can work for creating a robust knowledge graph. Also intelligent bots will have to depend on knowledge graphs if they are going to be useful for a common use cases </p>\n<h2>What's next for Walnut.Ai</h2>\n<p>Create a multi layer hierarchy to capture higher level concepts of the movie knowledge graph.\nTrain the model with a very large corpus of data \nCreate a test environment to continuously test the knowledge graph and introduce inhibitory connections</p>\n</div>\n<div class=\"\" id=\"built-with\">\n<h2>Built With</h2>\n<ul class=\"no-bullet inline-list\"><li><span class=\"cp-tag\">nupic</span></li><li><span class=\"cp-tag\">propritery-ai</span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/python\">python</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/json\">json</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/love\">love</a></span></li><li><span class=\"cp-tag recognized-tag\"><a href=\"https://devpost.com/software/built-with/django\">django</a></span></li></ul>\n</div>\n</div>", ["I conceptualized and built the HTM Challenge project. With thanks to the Nupic community for their support"]]]